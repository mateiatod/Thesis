{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llr_SBwHhvSn",
        "outputId": "1c0d917e-c148-4c4a-894b-fcbf6f926c42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.callbacks import LambdaCallback\n",
        "from keras import backend as K\n",
        "from keras import activations\n",
        "import keras\n",
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import Callback\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "from scipy.stats import norm\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QkRd7PIhh_QC"
      },
      "outputs": [],
      "source": [
        "# Load arrays from Google Drive\n",
        "X_train = np.load('/content/drive/My Drive/X_train_new.npy')\n",
        "y_train = np.load('/content/drive/My Drive/y_train_new.npy')\n",
        "X_test = np.load('/content/drive/My Drive/X_test_new.npy')\n",
        "y_test = np.load('/content/drive/My Drive/y_test_new.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fBKrts9Ze_DW"
      },
      "outputs": [],
      "source": [
        "percent_considered = 10. # the minimum difference between the % of neurons in range that we want to check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jpxjfazSiBII"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(128, activation='relu', input_shape=(784,)))\n",
        "model.add(Dense(128, activation='relu', input_shape=(128,)))\n",
        "model.add(Dense(11, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ratio = 1\n",
        "ds_size = len(X_train)  * ratio\n",
        "batchsize_train = 128\n",
        "dense_size = 128\n",
        "n_batches = int(ds_size // batchsize_train)\n",
        "n_epochs = 3\n",
        "n_layers = 2"
      ],
      "metadata": {
        "id": "FoRcOXBDgBle"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJ3mLLgZiQfY",
        "outputId": "3c2a9164-bf8d-437f-debe-15d4ab473884"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "  4/516 [..............................] - ETA: 11s - loss: 2.2283 - accuracy: 0.2578 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0071s vs `on_train_batch_begin` time: 0.0285s). Check your callbacks.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "516/516 [==============================] - 11s 20ms/step - loss: 0.2884 - accuracy: 0.9184\n",
            "Epoch 2/3\n",
            "516/516 [==============================] - 8s 16ms/step - loss: 0.1152 - accuracy: 0.9657\n",
            "Epoch 3/3\n",
            "516/516 [==============================] - 7s 13ms/step - loss: 0.0793 - accuracy: 0.9767\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b6efc179570>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "shapes = (n_batches, batchsize_train, dense_size)\n",
        "layer_activations = []\n",
        "for _ in range(n_layers):\n",
        "  epochs = []\n",
        "  for i in range(n_epochs):\n",
        "    epochs.append(np.empty(shapes))\n",
        "  layer_activations.append(epochs)\n",
        "model_output = []\n",
        "weights = []\n",
        "\n",
        "class CustomCallback(Callback):\n",
        "    def __init__(self):\n",
        "        super(CustomCallback, self).__init__()\n",
        "        for i in range(n_layers):\n",
        "          model_output.append(model.layers[i].output)\n",
        "        # self.neuron_activations = []\n",
        "        self.ok = False #used for testing\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "      self.neuron_activations = []\n",
        "      for i in range(n_layers):\n",
        "        self.neuron_activations.append(layer_activations[i][epoch])\n",
        "      if epoch == 0: ## replace 0 with the epoch you wanna test\n",
        "        self.ok = True\n",
        "\n",
        "    def on_batch_begin(self, batch, logs=None):\n",
        "        get_activations = K.function([model.layers[0].input], model_output)\n",
        "        if batch != (n_batches):  # we ignore the last, uncompleted batch so we can have a matrix\n",
        "          get_act = get_activations([X_train[(batch) * batchsize_train: (batch + 1) * batchsize_train]])\n",
        "          for i in range(n_layers):\n",
        "            activations = get_act[i]\n",
        "            self.neuron_activations[i][batch]= np.array(activations)\n",
        "\n",
        "custom_callback = CustomCallback()\n",
        "\n",
        "model.fit(X_train, y_train, epochs=n_epochs, batch_size=batchsize_train, callbacks=[custom_callback])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgIW3xoldCW6"
      },
      "source": [
        "Properly arrange list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-ERpISfWkVd0"
      },
      "outputs": [],
      "source": [
        "neuron_activations = []\n",
        "for j in range(n_layers):\n",
        "  for i in range(n_epochs):\n",
        "    layer_activations[j][i] = np.reshape(layer_activations[j][i], (n_batches * batchsize_train, dense_size ))\n",
        "    layer_activations[j][i] = layer_activations[j][i].T.reshape((dense_size,-1))\n",
        "  neuron_activations.append(np.hstack(layer_activations[j]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQSwmBwoMKZ5"
      },
      "source": [
        "Sort based on class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nN8MusKhEqAo"
      },
      "outputs": [],
      "source": [
        "activations_class = []\n",
        "for layer_ in range(n_layers):\n",
        "  layer = []\n",
        "  for neuron_ in range(dense_size):\n",
        "    neuron_class = []\n",
        "    for class_ in range(11):\n",
        "      neuron_class.append([])\n",
        "    for image_ in range(n_epochs * n_batches * batchsize_train):\n",
        "      label = np.argmax(y_train[image_ % (n_batches * batchsize_train)])\n",
        "      neuron_class[label].append(neuron_activations[layer_][neuron_][image_])\n",
        "    layer.append(neuron_class)\n",
        "  activations_class.append(layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMQEwhb6O3SW"
      },
      "outputs": [],
      "source": [
        "(curr_layer, curr_neuron, curr_class) = 1, 2, 3\n",
        "(curr_layer2, curr_neuron2, curr_class2) = 1, 2, 2\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
        "\n",
        "axs[0].hist(activations_class[curr_layer][curr_neuron][curr_class], bins=20, color='skyblue', edgecolor='black')\n",
        "axs[0].set_title(f'layer = {curr_layer} neuron = {curr_neuron} class = {curr_class}')\n",
        "axs[0].set_xlabel('Value')\n",
        "axs[0].set_ylabel('Frequency')\n",
        "\n",
        "axs[1].hist(activations_class[curr_layer2][curr_neuron2][curr_class2], bins=20, color='salmon', edgecolor='black')\n",
        "axs[1].set_title(f'layer = {curr_layer2} neuron = {curr_neuron2} class = {curr_class2}')\n",
        "axs[1].set_xlabel('Value')\n",
        "axs[1].set_ylabel('Frequency')\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Standard deviation"
      ],
      "metadata": {
        "id": "jkXiOKeGhyQ0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5qhs2f4Np3G"
      },
      "outputs": [],
      "source": [
        "x_std = 1.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iB-xGiBANaM1"
      },
      "outputs": [],
      "source": [
        "neurons_mstd = np.empty((n_layers, dense_size, 11,2))\n",
        "for layer_ in range(n_layers):\n",
        "  for neuron_ in range(dense_size):\n",
        "    for class_ in range(11):\n",
        "      mean = np.mean(activations_class[layer_][neuron_][class_])\n",
        "      std = np.std(activations_class[layer_][neuron_][class_])\n",
        "      neurons_mstd[layer_][neuron_][class_][0] = mean - x_std * std\n",
        "      neurons_mstd[layer_][neuron_][class_][1] = mean + x_std * std\n",
        "range_classes = neurons_mstd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4kLH-EPmeBB"
      },
      "source": [
        "Create random list to get out of range"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRhYfLyImdi2"
      },
      "outputs": [],
      "source": [
        "random_X_test = np.random.choice([-1., 1.], size=(11000, 784), p=[0.5, 0.5])\n",
        "random_X_test += np.random.rand(11000, 784)  # Add random values between 0 and 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUQ09B_byBFe"
      },
      "source": [
        "Get activations from tests and random tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ooX0CIGe_NC"
      },
      "outputs": [],
      "source": [
        "get_testing_a = K.function([model.layers[0].input],\n",
        "                                  model_output)\n",
        "get_label_pred = K.function([model.layers[0].input],\n",
        "                                  [model.layers[-1].output])\n",
        "layers_output_random = get_testing_a([random_X_test])\n",
        "label_pred_random = get_label_pred([random_X_test])[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzuuVj-pf-Pi"
      },
      "outputs": [],
      "source": [
        "max_indices = np.argmax(label_pred_random, axis=1) # having the right label eg 7 or 4\n",
        "y_test_predict_random = np.zeros((max_indices.size, 11))\n",
        "y_test_predict_random[np.arange(max_indices.size), max_indices] = 1 # one hot encoded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHIhgG_jD6fl"
      },
      "source": [
        "Find correlation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6og5qD47D5zj"
      },
      "outputs": [],
      "source": [
        "def find_corr(array_v, array_bool):\n",
        "  numeric_boolean_values = array_bool.astype(int)\n",
        "  pearson_corr, pearson_p_value = pearsonr(array_v, numeric_boolean_values)\n",
        "  spearman_corr, spearman_p_value = spearmanr(array_v, numeric_boolean_values)\n",
        "  return pearson_corr, pearson_p_value, spearman_corr, spearman_p_value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73n_aLIhTmk0"
      },
      "source": [
        "Rearrange the list properly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a22r2qzMTlU-"
      },
      "outputs": [],
      "source": [
        "layers_output_random = np.array(layers_output_random)\n",
        "layers_output_random = layers_output_random.transpose(0, 2, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xiCPFg3vbhN1"
      },
      "outputs": [],
      "source": [
        "n_images_random = len(random_X_test)\n",
        "percentages_random = np.empty((n_images_random, 11))\n",
        "for i in range(n_images_random):\n",
        "  for class_ in range(11):\n",
        "    count = 0\n",
        "    for layer in range(n_layers):\n",
        "      for neuron in range(dense_size):\n",
        "        if range_classes[layer][neuron][class_][0] <= layers_output_random[layer][neuron][i] <= range_classes[layer][neuron][class_][1]:\n",
        "          count +=1\n",
        "    percentages_random[i][class_] = count / (n_layers * dense_size) * 100"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "difference_list_rand = np.zeros(len(percentages_random), dtype=bool)\n",
        "percentage_prediction_rand = np.zeros(len(percentages_random),dtype=bool)\n",
        "interesting_rand = []\n",
        "for percent_list_ in range(len(percentages_random)):\n",
        "  percent_list = percentages_random[percent_list_]\n",
        "  label_predict = np.argmax(percent_list)\n",
        "  percentage_prediction_rand[percent_list_] = (label_predict == 10)\n",
        "  check_difference = False\n",
        "  for percent in percent_list:\n",
        "    if abs(percent - percent_list[label_predict]) <= percent_considered and percent != percent_list[label_predict]:\n",
        "      check_difference = True\n",
        "      difference_list_rand[percent_list_] = True\n",
        "      break\n",
        "  if not check_difference :\n",
        "    interesting_rand.append(percent_list)"
      ],
      "metadata": {
        "id": "jaI4LROEEgiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find Correlation and Accuracy for NonImage inputs"
      ],
      "metadata": {
        "id": "0oD0qf4pytD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_wins_diff_rand = 0\n",
        "for i in range(len(difference_list_rand)):\n",
        "  if difference_list_rand[i] and percentage_prediction_rand[i]:\n",
        "    n_wins_diff_rand += 1"
      ],
      "metadata": {
        "id": "rg-TxFDXFsRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr_p_rand, p_p_rand, corr_s_rand, s_p_rand = find_corr(difference_list_rand, percentage_prediction_rand)"
      ],
      "metadata": {
        "id": "5RaTPcNeFj5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_diff_rand = np.sum(difference_list_rand)\n",
        "n_wins_rand = np.sum(percentage_prediction_rand)\n",
        "print(f'Accuracy when there is a < 10% difference: {n_wins_diff_rand/n_diff_rand}')\n",
        "print(f'Accuracy when there is a >= 10% difference: : {(n_wins_rand - n_wins_diff_rand)/(len(percentage_prediction_rand) - n_diff_rand)}')\n",
        "print(f'Pearson Correlation: {corr_p_rand} p-value:{p_p_rand}')\n",
        "print(f'Spearman Correlation: {corr_s_rand} p-value:{s_p_rand}')"
      ],
      "metadata": {
        "id": "EJbb0vldbkak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eULxKsuHRX4T"
      },
      "source": [
        "Compute Correlation and Accuracy for Image input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHJpB7TsdQ-s"
      },
      "outputs": [],
      "source": [
        "layers_output = get_testing_a([X_test])\n",
        "label_pred = get_label_pred([X_test])[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4T29ME7dXmO"
      },
      "outputs": [],
      "source": [
        "max_indices = np.argmax(label_pred, axis=1) # having the right label eg 7 or 4\n",
        "y_test_predict = np.zeros((max_indices.size, 11))\n",
        "y_test_predict[np.arange(max_indices.size), max_indices] = 1 # one hot encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7FCslXkddVn"
      },
      "outputs": [],
      "source": [
        "layers_output= np.array(layers_output)\n",
        "layers_output = layers_output.transpose(0, 2, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vwiOKLOlq8FY"
      },
      "outputs": [],
      "source": [
        "n_images = len(y_test)\n",
        "percentages = np.empty((n_images, 11))\n",
        "for i in range(n_images):\n",
        "  for class_ in range(11):\n",
        "    count = 0\n",
        "    for layer in range(n_layers):\n",
        "      for neuron in range(dense_size):\n",
        "        if range_classes[layer][neuron][class_][0] <= layers_output[layer][neuron][i] <= range_classes[layer][neuron][class_][1]:\n",
        "          count +=1\n",
        "    percentages[i][class_] = count / (n_layers * dense_size) * 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyBJWrgpuUTw"
      },
      "source": [
        "Check which predictions are right"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3F1yG1bed260"
      },
      "outputs": [],
      "source": [
        "a = np.array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "difference_list = np.zeros(len(percentages), dtype=bool)\n",
        "percentage_prediction = np.zeros(len(percentages),dtype=bool)\n",
        "for percent_list_ in range(len(percentages)):\n",
        "  percent_list = percentages[percent_list_]\n",
        "  label_predict = np.argmax(percent_list)\n",
        "  percentage_prediction[percent_list_] = (label_predict == np.argmax(y_test[percent_list_]))\n",
        "  check_difference = False\n",
        "  for percent in percent_list:\n",
        "    if abs(percent - percent_list[label_predict]) <= percent_considered and percent != percent_list[label_predict]:\n",
        "      check_difference = True\n",
        "      difference_list[percent_list_] = True\n",
        "      break"
      ],
      "metadata": {
        "id": "a_AwBdU1mnLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_wins_diff = 0\n",
        "for i in range(len(difference_list)):\n",
        "  if difference_list[i] and percentage_prediction[i]:\n",
        "    n_wins_diff += 1"
      ],
      "metadata": {
        "id": "pNeRAOVfSsDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr_p, p_p, corr_s, s_p = find_corr(difference_list, percentage_prediction)"
      ],
      "metadata": {
        "id": "SLdbAeov5QAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_diff = np.sum(difference_list)\n",
        "n_wins = np.sum(percentage_prediction)\n",
        "print(f'Accuracy when there is a < 10% difference: {n_wins_diff/n_diff}')\n",
        "print(f'Accuracy when there is a >= 10% difference: {(n_wins - n_wins_diff)/(len(percentage_prediction) - n_diff)}')\n",
        "print(f'Pearson Correlation: {corr_p} p-value:{p_p}')\n",
        "print(f'Spearman Correlation: {corr_s} p-value:{s_p}')"
      ],
      "metadata": {
        "id": "ZFshHrAXeQrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1dmGzSEchx4H"
      },
      "outputs": [],
      "source": [
        "av_perc_random = np.empty(len(percentages_random))\n",
        "for i in range(len(av_perc_random)):\n",
        "  av_perc_random[i] = np.sum(percentages_random[i])/11\n",
        "print(f'average random percentage is {np.sum(av_perc_random)/len(av_perc_random)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNcnsg2Uhzcc"
      },
      "outputs": [],
      "source": [
        "av_perc = np.empty(len(percentages))\n",
        "for i in range(len(av_perc)):\n",
        "  av_perc[i] = np.sum(percentages[i])/11\n",
        "print(f'averagepercentage is {np.sum(av_perc)/len(av_perc)}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5yqLb7VlBkJT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}